<div align="center">
<h1 align="center">实验验证</h1>

![GitHub](https://img.shields.io/github/license/Sensorjang/HierFL_exp)
![Language](https://img.shields.io/badge/Language-Python-blue)

</div>

源码来自论文《Client-Edge-Cloud Hierarchical Federated Learning》https://paperswithcode.com/paper/edge-assisted-hierarchical-federated-learning
数据集为mnist及cifar-10，模型包括cnn和resnet。


内容介绍：该论文将模型聚合分为两个阶段：边缘聚合和云聚合。

设有一个云服务器，L个边缘服务器，每个边缘服务器都有不相交的设备集D_n.

D_n中的设备进行本地更新，上传模型至边缘服务器n，边缘服务器聚合D_n中的设备提交的参数，并发回进行下一轮更新；完成一定数量的边缘聚合后，L个边缘服务器上传模型至云服务器进行一轮全局聚合。（以节省通信开销）。

设每轮边缘聚合需要经过K1轮本地更新，每轮云聚合（epoch）需要经过K2轮边缘聚合，故每轮云聚合共需K1K2轮本地更新。


修改要求：分为简化版本和noniid版本。

简化版本：需要能够调整
边缘服务器数量L，
每个边缘服务器的设备个数|D_n|，
每个设备的本地样本量s（各个设备样本量一致，从训练集划分），
以及轮次数K1、K2和迭代次数（云聚合次数）。
输出结果用三个数组打印（云聚合轮次数，全局精度，平均损失）。


Noniid版本：需要能够调整
边缘服务器数量L，
每个设备的本地样本量s（随机分布（可以是均匀分布），总数固定），
每轮边缘聚合中，每个边缘服务器的设备集D_n， 由论文和baseline的算法决定，
以及轮次数K1、K2和迭代次数（云聚合次数）。
输出结果用三个数组打印（云聚合轮次数，全局精度，平均损失）。

(项目为升级版本，主要使用多线程嵌套的方式封装了edge迭代和client迭代；修改了原项目的部分逻辑；新增部分数据集)

## 新增需求-2024.01.05
### 可选的训练方式：
- [x] 选项 0：正常训练，和之前的算法一样。
- [x] 选项 1：每轮边缘聚合中，每个 device 以概率 p 不上传它的模型参数（上传失败）。
- [x] 选项 2：每轮边缘聚合中，每个 device 以概率 p 将其模型参数上传给非与其配对的 server。每个非与其配对的 server 的接收模型的概率为 p/（m-1）。（m 为 server 数量），上传之后更新边
缘关联。
- 现存问题：基本流程经过多次测试，没有问题。但是存在方案上的问题：在1、2选项中，边缘迭代时边缘服务器的总样本量可能改变，此时云端聚合基于什么平均不清楚（以前不变的时候是直接在边缘总样本量上的平均，但现在每个边缘的总样本量不是一成不变的......）


### 训练数据集。
- [x] Shakespeare 数据集
  - [目前已经完成数据集的下载、预处理、装载、划分流程](datasets/shakespare)
  - [部署了RNN网络可以直接用于训练](models/shakespare_rnn.py)
  - 现存问题：
    - 数据集划分目前有点模糊，原数据集貌似已经划分好，直接读取就是143个客户且是niid的划分，实际没那么多客户，所以我将其读取后进行随机地合并、装载后分配给现有的客户
    - 训练精度很迷，目前在RNN上训练的精度很低，并且很快地收敛于一个定值，不知道是我的划分方法原因还是深度学习超参数的原因
  - 部分逻辑参考FedML框架
- [x] CelebA 数据集 （GAN 网络）
  - [目前已经完成数据集的一套流程](datasets/celeba)
  - [部署了GAN网络可以直接用于训练](models/celeba_gan.py)
  - 现存问题：
    - 这是一个多标签分类数据集(一张图片有多个标签)，本文不是很清楚这类数据的划分方式，目前就实现了随机iid划分，以其读取数据的标签套用了原来的niid划分逻辑
    - 训练精度也很迷，对学习率非常敏感，学习率稍微大一点精度直接拉到1、损失直接干到100，精度第一点损失只有2且精度无限接近1；另外，对于GAN的评估指标本人尚不清楚，目前云端对GAN的评估是基于判别器对真实样本和生成器生成的虚假样本的判别精度，但是这个指标不知道是否合理
 